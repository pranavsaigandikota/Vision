# Vision

![Vision Banner](https://github.com/pranavsaigandikota/Vision/blob/main/banner.jpg)

---

## App for Drawing with your Eyes and Voice

**Made by the amazing team:**  
Pranavsai Gandikota, Arwa Arshad Ali, David Navarrete, Peter-Karl Jackson

---

## How to Run

To try out Vision, you will need to:

- Update the file paths in the provided batch file to match your local environment.
- Install the required Python libraries listed in the requirements or setup files.

---

## Inspiration

Vision was created with the goal of developing an inclusive platform that empowers individuals, especially those with limited mobility, to express their artistic creativity. By leveraging advanced eye tracking and voice recognition technologies, we aim to remove barriers and make digital art creation accessible to everyone. (Also its really fun and cool to mess around with)

---

## What It Does

Vision allows users to draw on a virtual canvas using only their eyes and voice commands:

- **Eye tracking** controls the mouse pointer for precise drawing.
- **Voice recognition** changes brush colors and sizes dynamically.
- This hands-free approach creates an accessible and interactive digital art experience.

---

## How We Built It

Vision was developed using:

- **Python** – Core programming language.
- **OpenCV** – For image processing and eye tracking.
- **Pygame** – To build the interactive drawing canvas and manage inputs.
- **Speech Recognition** – To handle voice commands.
- **Visual Studio Code** – IDE for development and debugging.

---

## Challenges We Ran Into

- Achieving accurate and reliable eye tracking required extensive calibration and testing.
- Ensuring high voice command recognition accuracy, especially in noisy environments.
- Designing an intuitive UI for users with diverse accessibility needs.

---

## Accomplishments We're Proud Of

- Creating a fully functional application integrating eye tracking and voice recognition.
- Delivering a user-friendly and accessible platform that enables creative freedom for users with limited mobility.

---

## What We Learned

- The critical role of user feedback in improving usability and functionality.
- Techniques to optimize eye tracking accuracy.
- Implementing robust, real-time speech recognition.

---

## What’s Next for Vision

- Add more customizable brushes and artistic tools.
- Enhance voice recognition with more commands and multilingual support.
- Conduct user testing to gather feedback and iterate on the design.
- Explore online integration for easy sharing of artwork.

---

Feel free to explore the code and contribute!  
If you have questions or feedback, please open an issue or reach out.

---

**Repository:** [https://github.com/pranavsaigandikota/Vision](https://github.com/pranavsaigandikota/Vision)
